{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pauli\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plots_file import *\n",
    "from our_functionsv3 import *\n",
    "\n",
    "np.random.seed(0)\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_data(pos = \"twitter-datasets/train_pos_preprocessed.txt\", neg = \"twitter-datasets/train_neg_preprocessed.txt\")\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, _ = get_test_data(\"twitter-datasets/test_data.txt\")\n",
    "X_test = read_data(\"twitter-datasets/test_preprocessed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = get_max_length(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_length)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 797s 4ms/step - loss: 0.5210 - acc: 0.7248 - val_loss: 0.4849 - val_acc: 0.7575\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 777s 4ms/step - loss: 0.4768 - acc: 0.7606 - val_loss: 0.4718 - val_acc: 0.7651\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 781s 4ms/step - loss: 0.4594 - acc: 0.7744 - val_loss: 0.4577 - val_acc: 0.7772\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 775s 4ms/step - loss: 0.4454 - acc: 0.7847 - val_loss: 0.4757 - val_acc: 0.7673\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 929s 5ms/step - loss: 0.4352 - acc: 0.7913 - val_loss: 0.4453 - val_acc: 0.7883\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 1020s 6ms/step - loss: 0.4299 - acc: 0.7967 - val_loss: 0.4425 - val_acc: 0.7851\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 1080s 6ms/step - loss: 0.4234 - acc: 0.8009 - val_loss: 0.4447 - val_acc: 0.7885\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 1167s 6ms/step - loss: 0.4172 - acc: 0.8048 - val_loss: 0.4385 - val_acc: 0.7898\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 1103s 6ms/step - loss: 0.4141 - acc: 0.8082 - val_loss: 0.4636 - val_acc: 0.7861\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 1070s 6ms/step - loss: 0.4170 - acc: 0.8066 - val_loss: 0.4422 - val_acc: 0.7905\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 1042s 6ms/step - loss: 0.4088 - acc: 0.8099 - val_loss: 0.4535 - val_acc: 0.7927\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 1232s 7ms/step - loss: 0.4025 - acc: 0.8144 - val_loss: 0.4518 - val_acc: 0.7904\n",
      "Epoch 13/50\n",
      "180000/180000 [==============================] - 878s 5ms/step - loss: 0.4037 - acc: 0.8138 - val_loss: 0.4563 - val_acc: 0.7915\n",
      "Epoch 14/50\n",
      "180000/180000 [==============================] - 713s 4ms/step - loss: 0.3978 - acc: 0.8190 - val_loss: 0.4653 - val_acc: 0.7895\n",
      "Epoch 00014: early stopping\n",
      "Model took 13367.014552593231 seconds (which is 222.78357587655384 minutes or 3.7130595979425642 hours) to train\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 846s 5ms/step - loss: 0.5263 - acc: 0.7165 - val_loss: 0.5004 - val_acc: 0.7385\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 772s 4ms/step - loss: 0.4805 - acc: 0.7540 - val_loss: 0.4764 - val_acc: 0.7548\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 749s 4ms/step - loss: 0.4644 - acc: 0.7661 - val_loss: 0.4730 - val_acc: 0.7570\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 727s 4ms/step - loss: 0.4548 - acc: 0.7720 - val_loss: 0.4641 - val_acc: 0.7685\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 721s 4ms/step - loss: 0.4486 - acc: 0.7758 - val_loss: 0.4586 - val_acc: 0.7696\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 719s 4ms/step - loss: 0.4435 - acc: 0.7801 - val_loss: 0.4534 - val_acc: 0.7746\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 713s 4ms/step - loss: 0.4393 - acc: 0.7829 - val_loss: 0.4510 - val_acc: 0.7749\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 722s 4ms/step - loss: 0.4359 - acc: 0.7849 - val_loss: 0.4489 - val_acc: 0.7774\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 719s 4ms/step - loss: 0.4327 - acc: 0.7876 - val_loss: 0.4499 - val_acc: 0.7770\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 723s 4ms/step - loss: 0.4301 - acc: 0.7888 - val_loss: 0.4509 - val_acc: 0.7794\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 720s 4ms/step - loss: 0.4276 - acc: 0.7906 - val_loss: 0.4475 - val_acc: 0.7764\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 723s 4ms/step - loss: 0.4245 - acc: 0.7927 - val_loss: 0.4464 - val_acc: 0.7772\n",
      "Epoch 13/50\n",
      "180000/180000 [==============================] - 721s 4ms/step - loss: 0.4228 - acc: 0.7934 - val_loss: 0.4515 - val_acc: 0.7739\n",
      "Epoch 00013: early stopping\n",
      "Model took 9578.139771699905 seconds (which is 159.63566286166508 minutes or 2.6605943810277517 hours) to train\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 724s 4ms/step - loss: 0.5382 - acc: 0.7069 - val_loss: 0.4954 - val_acc: 0.7450\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 718s 4ms/step - loss: 0.4807 - acc: 0.7579 - val_loss: 0.4700 - val_acc: 0.7614\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 713s 4ms/step - loss: 0.4582 - acc: 0.7729 - val_loss: 0.4592 - val_acc: 0.7739\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 716s 4ms/step - loss: 0.4434 - acc: 0.7834 - val_loss: 0.4486 - val_acc: 0.7775\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 715s 4ms/step - loss: 0.4322 - acc: 0.7902 - val_loss: 0.4477 - val_acc: 0.7801\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 713s 4ms/step - loss: 0.4230 - acc: 0.7957 - val_loss: 0.4434 - val_acc: 0.7892\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 715s 4ms/step - loss: 0.4144 - acc: 0.8013 - val_loss: 0.4325 - val_acc: 0.7865\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 721s 4ms/step - loss: 0.4054 - acc: 0.8069 - val_loss: 0.4417 - val_acc: 0.7877\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 718s 4ms/step - loss: 0.3963 - acc: 0.8124 - val_loss: 0.4307 - val_acc: 0.7916\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 714s 4ms/step - loss: 0.3870 - acc: 0.8176 - val_loss: 0.4349 - val_acc: 0.7893\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 713s 4ms/step - loss: 0.3780 - acc: 0.8229 - val_loss: 0.4402 - val_acc: 0.7895\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 718s 4ms/step - loss: 0.3689 - acc: 0.8275 - val_loss: 0.4435 - val_acc: 0.7877\n",
      "Epoch 00012: early stopping\n",
      "Model took 8603.373971223831 seconds (which is 143.38956618706385 minutes or 2.389826103117731 hours) to train\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 714s 4ms/step - loss: 0.5209 - acc: 0.7238 - val_loss: 0.4859 - val_acc: 0.7493\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 710s 4ms/step - loss: 0.4740 - acc: 0.7601 - val_loss: 0.4719 - val_acc: 0.7530\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 710s 4ms/step - loss: 0.4543 - acc: 0.7743 - val_loss: 0.4550 - val_acc: 0.7763\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 711s 4ms/step - loss: 0.4396 - acc: 0.7843 - val_loss: 0.4417 - val_acc: 0.7810\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 711s 4ms/step - loss: 0.4296 - acc: 0.7902 - val_loss: 0.4394 - val_acc: 0.7833\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 711s 4ms/step - loss: 0.4205 - acc: 0.7970 - val_loss: 0.4344 - val_acc: 0.7871\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 712s 4ms/step - loss: 0.4110 - acc: 0.8028 - val_loss: 0.4339 - val_acc: 0.7857\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 712s 4ms/step - loss: 0.4028 - acc: 0.8069 - val_loss: 0.4553 - val_acc: 0.7919\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 707s 4ms/step - loss: 0.3939 - acc: 0.8121 - val_loss: 0.4429 - val_acc: 0.7890\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 714s 4ms/step - loss: 0.3845 - acc: 0.8175 - val_loss: 0.4311 - val_acc: 0.7955\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 708s 4ms/step - loss: 0.3762 - acc: 0.8238 - val_loss: 0.4461 - val_acc: 0.7895\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 704s 4ms/step - loss: 0.3674 - acc: 0.8281 - val_loss: 0.4531 - val_acc: 0.7948\n",
      "Epoch 13/50\n",
      "180000/180000 [==============================] - 712s 4ms/step - loss: 0.3588 - acc: 0.8329 - val_loss: 0.4419 - val_acc: 0.7874\n",
      "Epoch 00013: early stopping\n",
      "Model took 9240.140751838684 seconds (which is 154.00234586397806 minutes or 2.5667057643996345 hours) to train\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180000/180000 [==============================] - 719s 4ms/step - loss: 0.6657 - acc: 0.5532 - val_loss: 0.5645 - val_acc: 0.6923\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 719s 4ms/step - loss: 0.5008 - acc: 0.7418 - val_loss: 0.4704 - val_acc: 0.7615\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 716s 4ms/step - loss: 0.4597 - acc: 0.7716 - val_loss: 0.4575 - val_acc: 0.7689\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 714s 4ms/step - loss: 0.5004 - acc: 0.7394 - val_loss: 0.4929 - val_acc: 0.7469\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 717s 4ms/step - loss: 0.4562 - acc: 0.7764 - val_loss: 0.4562 - val_acc: 0.7781\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 715s 4ms/step - loss: 0.4299 - acc: 0.7931 - val_loss: 0.4404 - val_acc: 0.7860\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 716s 4ms/step - loss: 0.4161 - acc: 0.8020 - val_loss: 0.4333 - val_acc: 0.7864\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 714s 4ms/step - loss: 0.4040 - acc: 0.8094 - val_loss: 0.4303 - val_acc: 0.7919\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 716s 4ms/step - loss: 0.4228 - acc: 0.7983 - val_loss: 0.4555 - val_acc: 0.7817\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 723s 4ms/step - loss: 0.4250 - acc: 0.7984 - val_loss: 0.4552 - val_acc: 0.7826\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 715s 4ms/step - loss: 0.4164 - acc: 0.8024 - val_loss: 0.4697 - val_acc: 0.7750\n",
      "Epoch 00011: early stopping\n",
      "Model took 7887.099268913269 seconds (which is 131.45165448188783 minutes or 2.1908609080314636 hours) to train\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "models = []\n",
    "\n",
    "optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "for opt in optimizer:\n",
    "    history, model = complete_model(X_train_indices, Y_train_oh, word_to_vec_map, word_to_index, max_length, summary = False, dropout_rate = 0.5, batch_size = 128, \n",
    "                                     epochs = 50, loss ='binary_crossentropy', optimizer = opt)\n",
    "    histories.append(history)\n",
    "    models.append(model)\n",
    "    label = new_predict_lstm(model, X_test_indices)\n",
    "    path = 'submissions/submission_model_optimizer_'+ opt + '_.csv'\n",
    "    create_csv_submission(ids, label, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "models = []\n",
    "\n",
    "optimizer = ['adam']\n",
    "for opt in optimizer:\n",
    "    history, model = complete_model(X_train_indices, Y_train_oh, word_to_vec_map, word_to_index, max_length, summary = False, dropout_rate = 0.5, batch_size = 128, \n",
    "                                     epochs = 50, loss ='binary_crossentropy', optimizer = opt)\n",
    "    histories.append(history)\n",
    "    models.append(model)\n",
    "    label = new_predict_lstm(model, X_test_indices)\n",
    "    path = 'submissions/submission_model_1_output_.csv'\n",
    "    create_csv_submission(ids, label, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
