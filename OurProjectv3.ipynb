{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read:\n",
    "This file is a good start to be able to use the data correctly with all the same structure and all.  \n",
    "You do not need anymore to tell the size of the vector from words embedding (it is found by the functions themselves).  \n",
    "Plus, the Y are transformed to -1 -> 0 from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from our_functionsv3 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_data function create two arrays of data from the .txt files.\n",
    "\n",
    "X is an array containing one phrase in each line  \n",
    "Y is an array containing the label of one phrase in each line with 0 meaning :( and 1 meaning :)\n",
    "\n",
    "With train_neg.txt:\n",
    "\n",
    "X size = (200000,)  \n",
    "Y size = (200000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_data(\"./datasets/train_neg.txt\", \"./datasets/train_pos.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_prepro function delete all the tweets that are the same.  \n",
    "<font color='red'>However, as the data are shuffled in get_data, I think that the supressing is not working</font>  \n",
    "So for now on, this function is disabled in our_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep, Y_prep = train_prepro(X,Y) #preprocessing de nos data_train\n",
    "#X, Y = X_prep, Y_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a embeddings dictionnary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read_glove_vecs create dictionnary from the datasets found on internet.  \n",
    "With twitterdict.txt : dict length is 1193514 and the size is 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('datasets/twitterdict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.43436667  0.278057    0.19971233  0.02544    -0.84125    -0.24157333\n",
      "  1.80756667  0.47475067 -0.93512333  0.19803    -0.87362333  0.25682533\n",
      " -5.6514     -0.56852    -0.76401333  0.223002    0.307989   -0.73013\n",
      " -0.3427     -0.16396667  0.23413333  0.135265   -0.16045367  0.54171333\n",
      " -0.20173333]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"I love you\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is:\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64\n",
      "Accuracy: 0.68\n",
      "Accuracy: 0.66\n",
      "Accuracy: 0.62\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.58\n",
      "Accuracy: 0.56\n",
      "Accuracy: 0.54\n",
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_prep[:50], Y_prep[:50], word_to_vec_map, learning_rate = 0.01, num_iterations = 10,size=25)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
