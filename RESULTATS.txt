Accuracy de tous les résultats

-------------------------------------------------------------------------------------------------------------------------
------------- 1. BASELINE: Notebook Version 1 avec dictionnaire du cours et data (pas de preprocessing) -----------------
-------------------------------------------------------------------------------------------------------------------------
- Learning rate = 0.0005 
Accuracy_train = 60%
Accuracy Kaggle =

- Learning rate = 0.005 
Accuracy_train = 61% puis stagne
Accuracy Kaggle = 61%

- Learning rate = 0.05
Accuracy_train = 0.52% puis stagne

Defaults: apprend très vite puis stagne. Peu importe le learning rate. Apprend trop lentement car SGD. 

Idées pour le moment: plus de pre-processing pour avoir quelque chose de plus robuste

----------------------------------------------------------------------------------------------------------------------
------------- 2. Notebook Version 1 avec dictionnaire du cours et data ( avec preprocessing) -------------------------
----------------------------------------------------------------------------------------------------------------------
- Learning rate = 0.005 
Accuracy_train = 0.56

- Learning rate = 0.0005 -0.00075 - 0.001
Accuracy_train = 0.57

- Learning rate = 0.05
Accuracy_train = 0.50


----------------------------------------------------------------------------------------------------------------------
---3. Notebook Version 1 avec dictionnaire du cours et data ( avec preprocessing mais sans enlever stopwords) --------
----------------------------------------------------------------------------------------------------------------------
- Learning rate = 0.005 
Accuracy_train = 0.594

- Learning rate = 0.001
Accuracy_train = 0.589

- Learning rate = 0.0005
Accuracy_train = 0.605

- Learning rate = 0.0001
Accuracy_train = 0.584


Idées: utiliser un autre dictionnaire est peut-être mieux. 



*********************************************************************************************************************
*********************************************************************************************************************
---------------------------------------------------------------------------------------------------------------------
------------- 4. Notebook Version 3 avec dictionnaire de twitter et data (avec preprocessing) -----------------------
---------------------------------------------------------------------------------------------------------------------
JEROME ET AUDREY
- Learning rate = 0.005 
Accuracy_train =

- Learning rate = 0.05
Accuracy_train = 

Defaults, moyenne = pas une variable très stable, 
Deux phrases très différentes peuvent avoir le même moyenne et pas dire la même chose ex: "Je l'aime à mourir" / "J'aimerais mourir"
Prend pas en compte ordre des mots et grande importance dans phrase en fait: "Je suis terriblement..." "heureux" ou "inquiet"

Idée: RNN and in particular, LSTM


*********************************************************************************************************************
*********************************************************************************************************************


---------------------------------------------------------------------------------------------------------------------
------------- 5. Notebook LSTM avec YJ version:  data pas preprocessed et glove 50d.        -----------------------
---------------------------------------------------------------------------------------------------------------------
(not data full, only train_pos and train_neg)
--> early stopping 
	- Test on Kaggle: 0.49

---------------------------------------------------------------------------------------------------------------------
-------- 6. Notebook LSTM avec YJ version:  data preprocessed avec chiffres et signes seulement et glove 50d.        ----------
---------------------------------------------------------------------------------------------------------------------
(not data full, only train_pos and train_neg)
--> early stopping 
	- Train: 0.82  (3h20)
	- Test on Kaggle: SUBMIT submission_model__without_nb_and_symbols.csv


---------------------------------------------------------------------------------------------------------------------
------------- 7. Notebook LSTM avec YJ version:  data preprocessed et glove 50d.            -----------------------
---------------------------------------------------------------------------------------------------------------------
(not data full, only train_pos and train_neg)
--> 50 epochs
	- Train: 0.92
	- Test on Kaggle: 0.75
	Model took 800s * 50 to train

--> early stopping at epochs  
	- Train:
	- Test on Kaggle: 0.777
	in this case, kept history 
	Model took 6995.441886663437 seconds to train



TO TRY:
loss = binary crossentropy
dictionnaire de twitter
full dataset


password note hotcpr: aichyuiaeoiuoooeuow